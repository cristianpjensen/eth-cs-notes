\section{Paradigms of data science}

Let $\{ \vec{x}_1, \ldots, \vec{x}_n \}$ be i.i.d. samples, generated by an unknown distribution
$P$. Assume that this distribution is in a distribution family, \[
    \mathcal{H} = \{ p(\cdot \mid \vec{\theta}) \mid \vec{\theta} \in \Theta \}.
\]
The goal is to learn the parameters $\vec{\theta}$ that fit the data $\{ \vec{x}_1, \ldots,
    \vec{x}_n \}$ best.

\paragraph{Frequentism.}

In frequentism, the maximum likelihood estimator (MLE) parameters maximize the following,
\begin{align*}
    \vec{\theta}^\star & \in \argmax_{\vec{\theta} \in \Theta} \log p(\{ \vec{x}_1, \ldots, \vec{x}_n \} \mid \vec{\theta}) \\
                       & = \argmax_{\vec{\theta} \in \Theta} \sum_{i=1}^{n} \log p(\vec{x}_i \mid \vec{\theta}).
\end{align*}

\paragraph{Bayesianism.}

Bayesianism assumes that there is a prior over distributions. The maximum a posteriori (MAP)
parameters maximize the following,
\begin{align*}
    \vec{\theta}^\star & \in \argmax_{\vec{\theta} \in \Theta} \log p(\vec{\theta} \mid \mat{X})                                                                         \\
                       & = \argmax_{\vec{\theta} \in \Theta} \log p(\{ \vec{x}_1, \ldots, \vec{x}_n \} \mid \vec{\theta}) \cdot p(\vec{\theta}) \margintag{Bayes' rule.} \\
                       & = \argmax_{\vec{\theta} \in \Theta} \log p(\vec{\theta}) + \sum_{i=1}^{n} \log p(\vec{x}_i \mid \vec{\theta}).
\end{align*}
In practice, the prior acts as a regularization term.

\paragraph{Statistical learning.}

Now, assume that we have labeled samples $\{ (\vec{x}_1, y_1), \ldots, (\vec{x}_n, y_n) \}
    \subseteq \mathcal{X} \times \mathcal{Y}$, where $y$ is the target variable. Let $\ell: \mathcal{Y}
    \times \mathcal{Y} \to \R$ be a loss function. For a predictor function $f: \mathcal{X} \to
    \mathcal{Y}$, we define its risk as the expected loss, \[
    \mathcal{R}(f) \doteq \E_{X, Y} [\ell(y, f(\vec{x}))].
\]
In statistical learning, we want to find a function that minimizes the risk. However, since the
distribution over $X,Y$ is unknown, we cannot compute $\mathcal{R}(f)$ directly. Instead, we use
the empirical risk as a surrogate, \[
    \hat{\mathcal{R}}(f) \doteq \frac{1}{n} \sum_{i=1}^{n} \ell(y_i, f(\vec{x}_i)).
\]
The goal is to obtain the empirical risk minimizer, \[
    f^\star \in \argmin_{f \in \mathcal{F}} \hat{\mathcal{R}}(f),
\]
where $\mathcal{F}$ is a family of functions that we assume $f$ belongs to.
