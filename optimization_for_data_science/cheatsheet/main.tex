\documentclass[a4paper]{article}
% \documentclass[8pt,a4paper]{extarticle}

\usepackage[margin=0.25cm, showframe=true]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{multicol}
\usepackage{amsmath,amsfonts,amsthm,amssymb,mathrsfs,bbm,mathtools,nicefrac,bm,centernot,colonequals,dsfont}

\usepackage{derivative}
\usepackage[skip=.5\baselineskip-0.5pt]{parskip}
\usepackage[extreme, mathspacing=normal, leadingfraction=0.85]{savetrees}
\usepackage[document]{ragged2e}

\usepackage{enumitem}
\setlist[itemize]{leftmargin=0.4cm, label=$\circ$}
\setlist[enumerate]{leftmargin=0.4cm, label=[\arabic*]}

\usepackage{color,soul}
\usepackage{xcolor}

\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}

\newcommand{\lft}{\mathopen{}\mathclose\bgroup\left}
\newcommand{\rgt}{\aftergroup\egroup\right}

\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Var}{\mathrm{Var}}

\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\mat}[1]{#1}
\newcommand{\transpose}[1]{#1^\top}
\newcommand{\dom}[1]{\mathrm{dom}(#1)}

\newcommand{\proofsquare}{$\blacksquare$}

\renewcommand{\familydefault}{\sfdefault}

\setlength{\columnseprule}{0.4pt}

\title{Optimization for Data Science Cheatsheet}

\newenvironment{topic}[1]
{\textbf{\sffamily \colorbox{black}{\rlap{\textbf{\textcolor{white}{#1}}}\hspace{\linewidth}\hspace{-2\fboxsep}}} \\ \vspace{0.2cm}}
{}

\begin{document}

\setlength{\columnsep}{0.2cm}

\begin{multicols*}{2}
    \begin{topic}{Definitions}
        \begin{itemize}
            \item \textbf{Differentiable}: $f: \R^d \to \R$ is differentiable if \[
                      f(\vec{y}) = f(\vec{x}) + \langle \nabla f(\vec{x}), \vec{y} - \vec{x} \rangle + \frac{r(\vec{x} - \vec{y})}{\| \vec{x} - \vec{y} \|},
                  \]
                  where $\lim_{\vec{v} \to \vec{0}} \frac{\| r(\vec{v}) \|}{\| \vec{v} \|} = 0$.

            \item \textbf{Spectral norm}: $\| \mat{A} \|_2 = \sup_{\| \vec{x} \| = 1} \| \mat{A} \vec{x} \|$ (largest eigenvalue).
            \item \textbf{Positive semi-definite}: $\forall \vec{x} \in \R^d$: $\vec{x}^\top \mat{A} \vec{x} \geq 0$.
            \item \textbf{$B$-Lipschitz}: $\| f(\vec{x}) - f(\vec{y}) \| \leq B \| \vec{x} - \vec{y} \| \Leftrightarrow \| \nabla f(\vec{x}) \| \leq B$.
            \item \textbf{Convex set}: $\forall \vec{x}, \vec{y} \in X, \lambda \in [0,1]$: $\lambda \vec{x} + (1-\lambda) \vec{y} \in X$.
            \item \textbf{Convexity}: $\forall \vec{x}, \vec{y} \in \dom{f}$ and $\forall \lambda \in [0,1]$,
                  \begin{enumerate}
                      \item $f(\lambda \vec{x} + (1-\lambda)\vec{y}) \leq \lambda f(\vec{x}) + (1-\lambda) f(\vec{y})$.
                      \item $f(\vec{y}) \geq f(\vec{x}) + \langle \nabla f(\vec{x}), \vec{y} - \vec{x} \rangle$.
                      \item $\langle \nabla f(\vec{x}) + \nabla f(\vec{y}), \vec{x} - \vec{y} \rangle \geq 0$.
                      \item $\nabla^2 f(\vec{x})$ is positive semi-definite.
                  \end{enumerate}
            \item \textbf{$L$-smoothness}: $\forall \vec{x}, \vec{y} \in \dom{f}$,
                  \begin{enumerate}
                      \item $\| \nabla f(\vec{x}) - \nabla f(\vec{y}) \| \leq L \| \vec{x} - \vec{y} \|$.
                      \item $g(\vec{x}) := \frac{L}{2} \| \vec{x} \|^2 - f(\vec{x})$ is convex.
                      \item $f(\vec{y}) \leq f(\vec{x}) + \langle \nabla f(\vec{x}), \vec{y} - \vec{x} \rangle + \frac{L}{2} \| \vec{x} - \vec{y} \|^2$ (canonical).
                      \item $\langle \nabla f(\vec{x}) - \nabla f(\vec{y}), \vec{x} - \vec{y} \rangle \leq L \| \vec{x} - \vec{y} \|^2$.
                      \item $\| \nabla^2 f(\vec{x}) \|_2 \leq L$.
                      \item Coordinate-wise: $f(\vec{x} + \lambda \vec{e}_i) \leq f(\vec{x}) + \lambda \nabla_i f(\vec{x}) +
                                \frac{L_i}{2} \lambda^2, \forall \lambda \in \R$.
                  \end{enumerate}
                  Relations: $[5] \Leftrightarrow [1] \Rightarrow [2] \Leftrightarrow [3] \Leftrightarrow [4]$ (If convex, all $\Leftrightarrow$).
            \item \textbf{$\mu$-strong convexity}: $\forall \vec{x}, \vec{y} \in \dom{f}$,
                  \begin{enumerate}
                      \item $f(\vec{y}) \geq f(\vec{x}) + \langle \nabla f(\vec{x}), \vec{y} - \vec{x} \rangle + \frac{\mu}{2} \| \vec{x} - \vec{y} \|^2$.
                      \item $g(\vec{x}) := f(\vec{x}) - \frac{\mu}{2} \| \vec{x} \|^2$ is convex.
                      \item $\langle \nabla f(\vec{x}) - \nabla f(\vec{y}), \vec{x} - \vec{y} \rangle \geq \mu \| \vec{x} - \vec{y} \|^2$ (needs proof).
                      \item $\mu$-SC $\Rightarrow$ PL inequality: $\frac{1}{2} \| \nabla f(\vec{x}) \|^2 \geq \mu (f(\vec{x}) - f^\star)$.
                  \end{enumerate}
            \item \textbf{Subgradient}: $\vec{g} \in \partial f(\vec{x}) \Leftrightarrow f(\vec{y}) \geq f(\vec{x}) + \langle \vec{g}, \vec{y} - \vec{x} \rangle, \forall \vec{y} \in \dom{f}$.
            \item \textbf{Conjugate function}: $f^\star(\vec{y}) := \sup_{\vec{x} \in \dom{f}} \langle \vec{x}, \vec{y} \rangle - f(\vec{x})$.
        \end{itemize}
    \end{topic}

    \begin{topic}{Lemmas}
        \begin{itemize}
            \item \textbf{Cosine theorem}: All equivalent formulations,
                  \begin{enumerate}
                      \item $\| \vec{x} - \vec{y} \|^2 = \| \vec{x} \|^2 + \| \vec{y} \|^2 - 2 \langle \vec{x}, \vec{y} \rangle$.
                      \item $\langle \vec{x}, \vec{y} \rangle = \frac{1}{2} \lft( \| \vec{x} \|^2 + \| \vec{y} \|^2 - \| \vec{x} - \vec{y} \|^2 \rgt)$.
                      \item $\langle \vec{x} - \vec{y}, \vec{x} - \vec{z} \rangle = \frac{1}{2} \lft( \| \vec{x} - \vec{y} \|^2 + \| \vec{x} - \vec{z} \|^2 - \| \vec{y} - \vec{z} \|^2 \rgt)$.
                  \end{enumerate}
            \item \textbf{Cauchy-Schwarz}: $|\langle \vec{x}, \vec{y} \rangle| \leq \| \vec{x} \| \| \vec{y} \|$.
            \item \textbf{H\"older's inequality} (special case): $|\langle \vec{x}, \vec{y} \rangle| \leq \| \vec{x} \|_1 \| \vec{y} \|_\infty$.
            \item \textbf{Jensen's inequality} ($\varphi$ convex, $a_i \geq 0$): \\ $\varphi \lft( \frac{\sum_{i=1}^{m} a_i \vec{x}_i}{\sum_{i=1}^{m} a_i} \rgt) \leq \frac{\sum_{i=1}^{m} a_i \varphi(\vec{x}_i)}{\sum_{i=1}^{m} a_i}$.
            \item \textbf{Fenchel's inequality}: $\langle \vec{x}, \vec{y} \rangle \leq f(\vec{x}) + f^\star(\vec{x})$ \\ $\Rightarrow \langle \vec{x}, \vec{y} \rangle \leq \frac{1}{2} \lft( \| \vec{x} \|^2 + \| \vec{y} \|^2_\star \rgt)$.
            \item \textbf{Young's inequality} ($a,b \geq 0, \frac{1}{p} + \frac{1}{q} = 1$): $ab \leq \frac{a^p}{p} + \frac{b^q}{q}$ \\ $\Rightarrow \| \vec{x} \| \| \vec{y} \| \leq \frac{1}{2} \lft( \| \vec{x} \|^2 + \| \vec{y} \|^2 \rgt)$.
            \item $\frac{1}{\sqrt{d}} \| \vec{x} \|_2 \leq \| \vec{x} \|_\infty \leq \| \vec{x} \|_2 \leq \| \vec{x} \|_1 \leq \sqrt{d} \| \vec{x} \|_2$.
            \item $\| \mat{A} \vec{x} \| \leq \| \mat{A} \|_2 \| \vec{x} \|$.
            \item $\| \mat{A} \|_2 \leq \| \mat{A} \|_F$.
            \item \textbf{Mean-value theorem} ($h$ cont. on $[a,b]$, diff. on $(a,b)$): \[
                      h'(c) = \frac{h(b) - h(a)}{b-a}, \quad \exists c \in (a,b).
                  \]
            \item \textbf{Fund. theorem of calculus} ($h$ diff. on $[a,b]$, $h'$ cont. on $[a,b]$): \[
                      h(b) - h(a) = \int_a^b h'(t) \mathrm{d}t.
                  \]
            \item $\lft\| \int_0^1 \nabla h(t) \mathrm{d}t \rgt\| \leq \int_0^1 \| \nabla h(t) \| \mathrm{d}t$.
            \item $\int_0^1 c \mathrm{d}t = c, \quad \int_0^1 t \mathrm{d}t = \frac{1}{2}$.
            \item \textbf{Subgradient calculus}:
                  \begin{enumerate}
                      \item $h(\vec{x}) = \alpha f(\vec{x}) + \beta g(\vec{x}) \Rightarrow \partial h(\vec{x}) = \alpha \cdot \partial f(\vec{x}) + \beta \cdot g(\vec{x})$.
                      \item $h(\vec{x}) = f(\mat{A} \vec{x} + \vec{b}) \Rightarrow \partial h(\vec{x}) = \transpose{\mat{A}} \partial f(\mat{A} \vec{x} + \vec{b})$.
                      \item $h(\vec{x}) = \max f_i(\vec{x}) \Rightarrow \partial h(\vec{x}) = \mathrm{conv}(\{ \partial f_i(\vec{x}) \mid f_i(\vec{x}) = h(\vec{x}) \})$.
                  \end{enumerate}
        \end{itemize}
    \end{topic}

    \begin{topic}{Optimality lemmas (assume convexity)}
        The constrained and non-differentiable cases are useful when the update rule contains an $\argmin$.
        \begin{itemize}
            \item $\vec{x}^\star$ is a local minimum.
            \item $\nabla f(\vec{x}^\star) = \vec{0}$.
            \item Constrained: $\nabla f(\vec{x}^\star)^\top (\vec{x} - \vec{x}^\star) \geq 0, \forall \vec{x} \in
                      X$.
            \item Non-differentiable: $\vec{0} \in \partial f(\vec{x}^\star)$.
        \end{itemize}
    \end{topic}

    \begin{topic}{Common tricks}
        \begin{itemize}
            \item \textbf{Rearrange the update rule} for an equality---e.g., $\nabla f(\vec{x}_t) = \frac{\vec{x}_t -
                          \vec{x}_{t+1}}{\gamma_t}$.
            \item Define $h(t) := f(\vec{x} + t(\vec{y} - \vec{x}))$, where $h'(t) = \nabla f(\vec{x} + t(\vec{y} -
                      \vec{x}))^\top (\vec{y} - \vec{x})$ and use with fundamental theorem of calculus, \[
                      f(\vec{y}) - f(\vec{x}) = \int_0^1 \nabla f(\vec{x} + t(\vec{y} - \vec{x}))^\top (\vec{y} - \vec{x}) \mathrm{d}t.
                  \]
                  Or, mean-value theorem, \[
                      \nabla f(\vec{x} + c(\vec{y} - \vec{x}))^\top (\vec{y} - \vec{x}) = f(\vec{y}) - f(\vec{x}), \quad \exists c \in (0,1).
                  \]
            \item Projection is \textbf{non-expansive}: $\| \Pi_X(\vec{x}) - \Pi_X(\vec{y}) \| \leq \| \vec{x} -
                      \vec{y} \|$.
            \item $\min_{1 \leq t \leq T} f(\vec{x}_t) - f^\star \leq \frac{\sum_{t=1}^{T} \gamma_t (f(\vec{x}_t) - f^\star)}{\sum_{t=1}^{T} \gamma_t}$.
            \item \textbf{Telescoping sum} inequality:\\ $\sum_{t=1}^{T} \| \vec{x}_t - \vec{x}^\star \|^2 - \| \vec{x}_{t+1} -
                      \vec{x}^\star \| \leq \| \vec{x}_1 - \vec{x}^\star \|^2$.
            \item $f^\star \leq f(\vec{x}), \forall \vec{x} \in X$ can sometimes be useful to bound $f(\vec{x}_t) - f(\vec{x}_{t+1}) \leq f(\vec{x}_t) - f^\star$.
            \item $\max \{ a,b \} \leq a + b$ if $a,b \geq 0$.
        \end{itemize}
    \end{topic}

    \begin{topic}{Expectation and variance for SGD}
        \begin{itemize}
            \item $\Var[X] := \E\lft[ (X - \E[X])^2 \rgt]$
            \item $\Var[X] = \E[X^2] - \E[X]^2$ \\ $\Rightarrow \E \| \nabla f(\vec{x}_t, \vec{\xi}_t) \|^2 = \| \nabla F(\vec{x}_t) \|^2 + \E \| \nabla f(\vec{x}_t, \vec{\xi}_t) - \nabla F(\vec{x}_t) \|^2 \leq \| \nabla F(\vec{x}_t) \|^2 + \sigma^2$.
            \item \textbf{Law of total expectation}: $\E[X] = \E_Y[\E_X[X \mid Y]]$.
            \item \textbf{Law of total var.}: $\Var[Y] = \E_X[\Var_Y[Y \mid X]] + \Var_Y[\E_X[Y \mid X]]$.
            \item $\Var[X-Y] = \Var[X] + \Var[Y] - 2 \cdot \mathrm{Cov}(X, Y)$.
            \item $\Var[\alpha X] = \alpha^2 \Var[X]$, $\Var[X + \beta] = \Var[X]$.
        \end{itemize}
    \end{topic}

    \begin{topic}{Risk minimization}

    \end{topic}

    \begin{topic}{Non-linear programming}

    \end{topic}

    \begin{topic}{Gradient descent}
        \begin{itemize}
            \item \textbf{Update rule}: $\vec{x}_{t+1} = \vec{x}_t - \gamma \nabla f(\vec{x})$.
            \item \textbf{VA}: $\sum_{t=0}^{T-1} (f(\vec{x}_t) - f^\star) \leq \frac{\gamma}{2} \sum_{t=0}^{T-1} \| \nabla f(\vec{x}_t) \|^2 + \frac{1}{2 \gamma} \| \vec{x}_0 - \vec{x}^\star \|^2$.
            \item[\proofsquare] 1st-order convexity on $(\vec{x}^\star, \vec{x}_t)$ $\Rightarrow$ $\nabla f(\vec{x}_t) = \frac{\vec{x}_t - \vec{x}_{t+1}}{\gamma}$ $\Rightarrow$ Cosine theorem $\Rightarrow$ $\vec{x}_t - \vec{x}_{t+1} = \gamma \nabla f(\vec{x}_t)$ $\Rightarrow$ Telescoping sum.
            \item \textbf{Sufficient decrease}: $f(\vec{x}_{t+1}) \leq f(\vec{x}_t) - \frac{1}{2L} \| \nabla f(\vec{x}_t) \|^2$.
            \item[\proofsquare] Smoothness on ($\vec{x}_{t+1}, \vec{x}_t$) $\Rightarrow$ $\vec{x}_{t+1} - \vec{x}_t = -\frac{1}{L} \nabla f(\vec{x}_t)$.
            \item \textbf{Convergence results}: ($\| \vec{x}_0 - \vec{x}^\star \| \leq R$)
                  \begin{itemize}
                      \item ($B$-Lipschitz, convex, $\gamma := \frac{R}{B \sqrt{T}}$) $\frac{1}{T} \sum_{t=0}^{T-1} (f(\vec{x}_t) - f^\star) \leq \frac{RB}{\sqrt{T}}$.
                      \item[\proofsquare] Apply bounds to VA and find $\gamma$ by 1st-order optimality.
                      \item ($L$-smooth, convex, $\gamma := \frac{1}{L}$) $f(\vec{x}_T) - f^\star \leq \frac{L}{2T} \| \vec{x}_0 - \vec{x}^\star \|^2$
                      \item[\proofsquare] Sufficient decrease to bound gradients of VA with telescoping sum.
                      \item ($L$-smooth, $\mu$-SC, $\gamma := \frac{1}{L}$) $f(\vec{x}_T) - f^\star \leq \frac{L}{2} \lft( 1 - \frac{\mu}{L} \rgt)^T \| \vec{x}_0 - \vec{x}^\star \|^2$
                      \item[\proofsquare] Use $\mu$-SC to strengthen VA bound for squared norm $\Rightarrow$ Upper bound ``noise'' with $f^\star \leq f(\vec{x}_{t+1})$ and SD $\Rightarrow$ Smoothness on $(\vec{x}^\star, \vec{x}_T)$.
                  \end{itemize}
        \end{itemize}
    \end{topic}

    \begin{topic}{Projected gradient descent}
        \begin{itemize}
            \item \textbf{Update rule} ($X \subset \R^d$ is closed and convex):
                  \begin{align*}
                      \vec{y}_{t+1} & = \vec{x}_t - \gamma_t \nabla f(\vec{x}_t)                                                   \\
                      \vec{x}_{t+1} & = \Pi_X(\vec{y}_{t+1}) := \argmin_{\vec{x} \in \mathcal{X}} \| \vec{x} - \vec{y}_{t+1} \|^2.
                  \end{align*}
            \item ($\vec{x} \in X, \vec{y} \in \R^d$): $(\vec{x} - \Pi_X(\vec{y}))^\top (\vec{y} - \Pi_X(\vec{y})) \leq 0$.
            \item[\proofsquare] Constrained 1st-order optimality $\Rightarrow$ Rearrange.
            \item ($\vec{x} \in X, \vec{y} \in \R^d$): $\| \vec{x} - \Pi_X(\vec{y}) \|^2 + \| \vec{y} - \Pi_X(\vec{y}) \|^2 \leq \| \vec{x} - \vec{y} \|^2$.
            \item[\proofsquare] Cosine theorem on previous.
            \item If $\vec{x}_{t+1} = \vec{x}_t$, then $\vec{x}_t = \vec{x}^\star$.
            \item[\proofsquare] $(\vec{x} - \vec{x}_t)^\top (\vec{y}_{t+1} - \vec{x}_t) = (\vec{x} - \vec{x}_{t+1})^\top (\vec{y}_{t+1} - \vec{x}_{t+1}) \leq 0, \forall \vec{x} \in X$ to show that constrained 1st-order optimality holds.
            \item \textbf{Projected SD}:
            \item[\proofsquare]
            \item ($L$-smooth, convex, $\gamma := \frac{1}{L}$):
            \item[\proofsquare]
        \end{itemize}
    \end{topic}

    \begin{topic}{Coordinate descent}
        \begin{itemize}
            \item \textbf{Coordinate-wise SD}:
            \item[\proofsquare]
            \item \textbf{Convergence results} ($\mu$-PL, $\mathcal{L}$-CS, $\bar{L} = \frac{1}{d} \sum_{i=1}^{d} L_i$):
                  \begin{itemize}
                      \item ($i \sim \mathrm{Unif}([d])$)
                      \item[\proofsquare]
                      \item ($i \sim \mathrm{Cat}(\nicefrac{L_1}{\sum_{j=1}^{d} L_j}, \ldots, \nicefrac{L_d}{\sum_{j=1}^{d} L_j})$)
                      \item[\proofsquare]
                      \item ($i \in \argmax_{j\in[d]} |\nabla_j f(\vec{x}_t)|$)
                  \end{itemize}
        \end{itemize}
    \end{topic}

    \begin{topic}{Nonconvex functions}
        \begin{itemize}
            \item ($L$-smooth):
            \item[\proofsquare]
            \item \textbf{Trajectory analysis}: Optimize $f(\vec{x}) := \frac{1}{2} \lft( \prod_{k=1}^d x_k - 1 \rgt)^2$.
            \item $\pdv{f(\vec{x})}{x_i} = \lft( \prod_k x_k - 1 \rgt) \prod_{k\neq i} x_k$ ($\nabla f(\vec{x})=\vec{0}$ if 2 dims are $0$ or all $1$).
            \item $\pdv[order=2]{f(\vec{x})}{x_i} = \lft( \prod_{k\neq i} x_k \rgt)^2$.
            \item $\pdv{f(\vec{x})}{x_i,x_j} = 2 \prod_{k\neq i} x_k \prod_{k \neq j} x_k - \prod_{k\neq i,j} x_k$, if $i \neq j$.
            \item \textbf{$c$-balanced}: Let $\vec{x} > \vec{0}$, $c \geq 1$. $\vec{x}$ is $c$-balanced if $x_i \leq c \cdot x_j, \forall i, j \in [d]$.
            \item If $\vec{x}_t$ is $c$-balanced, $\gamma > 0$, then $\vec{x}_{t+1}$ is $c$-balanced and
                  $\vec{x}_{t+1} \geq \vec{x}_t$.
            \item[\proofsquare]
            \item If $\vec{x}$ is $c$-balanced, then for any $I \subseteq [d]$, we have \[
                      \prod_{k \not\in I} x_k \leq c^{|I|} \lft( \prod_{k=1}^d x_k \rgt)^{1 - \nicefrac{|I|}{d}} \leq c^{|I|}.
                  \]
            \item[\proofsquare]
            \item Let $\vec{x}$ be $c$-balanced and $\prod_k x_k \leq 1$, then \[
                      \| \nabla^2 f(\vec{x}) \|_2 \leq \| \nabla^2 f(\vec{x}) \|_F \leq 3dc^2.
                  \]
                  Thus, $f$ is smooth along the whole trajectory of GD.
            \item[\proofsquare]
            \item \textbf{Convergence} ($\gamma = \frac{1}{3dc^2}$, $\vec{x}_0 > \vec{0}$ and $c$-balanced, $\delta \leq \prod_k x_{0,k} < 1$) \\ $f(\vec{x}_T) \leq \lft( 1 - \frac{\delta^2}{3c^4} \rgt)^T f(\vec{x}_0)$.
            \item[\proofsquare]
            \item $\delta$ decays polynomially in $d$, so we must start $\mathcal{O}(\nicefrac{1}{\sqrt{d}})$ from $\vec{x}^\star = \vec{1}$.
        \end{itemize}
    \end{topic}

    \begin{topic}{Frank-Wolfe}
        \begin{itemize}
            \item $\mathrm{LMO}_X(\vec{g}) := \argmin_{\vec{z} \in X} \vec{g}^\top \vec{z}$.
            \item \textbf{Update rule}:
                  \begin{align*}
                      \vec{s}_t     & = \mathrm{LMO}_X(\nabla f(\vec{x}_t))          \\
                      \vec{x}_{t+1} & = (1-\gamma_t) \vec{x}_t + \gamma_t \vec{s}_t.
                  \end{align*}
            \item If $X = \mathrm{conv}(\mathcal{A})$, then $\mathrm{LMO}_X(\vec{g}) \in \mathcal{A}$.
            \item Advantages: (1) Iterates are always feasible if $X$ is convex, (2) No projections, (3) Iterates
                  have simple sparse representations as convex combination of $\{ \vec{x}_0, \vec{s}_0, \ldots,
                      \vec{s}_t \}$.
            \item LMO of unit $\ell_1$-ball: $\mathrm{LMO}(\vec{g}) = -\mathrm{sgn}(g_i) \vec{e}_i, i \in \argmax_{j
                          \in [d]} |g_i|$.
            \item \textbf{Optimality gap}: $g(\vec{x}) := \nabla f(\vec{x})^\top (\vec{x} - \vec{s}), \vec{s} = \mathrm{LMO}_X(\nabla f(\vec{x}))$.
            \item $g(\vec{x}) \geq f(\vec{x}) - f^\star$.
            \item[\proofsquare]
            \item \textbf{Descent lemma}: $f(\vec{x}_{t+1}) \leq f(\vec{x}_t) - \gamma_t g(\vec{x}_t) + \gamma_t^2 \frac{L}{2} \| \vec{s}_t - \vec{x}_t \|^2$.
            \item \textbf{Convergence} ($L$-smooth, convex, $X$ is compact, $\gamma_t = \frac{2}{t+2}$): \\ $f(\vec{x}_T) - f^\star \leq \frac{2L}{T+1} \mathrm{diam}(X)^2$.
            \item[\proofsquare] Lemma$-f^\star$ $\Rightarrow$ Use $g(\vec{x}) \geq f(\vec{x}) - f^\star$ $\Rightarrow$ Rearrange and induction.
            \item \textbf{Affine equivalence}: $(f, X)$ and $(f', X')$ are affinely equivalent if $f'(\vec{x}) = f(\mat{A} \vec{x} + \vec{b})$ and $X' = \{ \mat{A}^{-1}(\vec{x} - \vec{b}) \mid \vec{x} \in X \}$. Then,
                  \begin{align*}
                      \nabla f'(\vec{x}')                    & = \mat{A}^\top \nabla f(\vec{x}), \quad \vec{x} = \mat{A}^{-1} (\vec{x} - \vec{b})    \\
                      \mathrm{LMO}_{X'}(\nabla f'(\vec{x}')) & = \mat{A}^{-1}(\vec{s} - \vec{b}), \quad \vec{s} = \mathrm{LMO}_X(\nabla f(\vec{x})).
                  \end{align*}
            \item \textbf{Curvature constant}: \[
                      C_{(f,X)} := \sup_{\substack{\vec{x}, \vec{s}\in X, \gamma \in (0,1] \\ \vec{y} = (1-\gamma)\vec{x} + \gamma \vec{s})}} \frac{1}{\gamma^2}\lft( f(\vec{y}) - f(\vec{x}) - \nabla f(\vec{x})^\top (\vec{y} - \vec{x}) \rgt).
                  \]
            \item \textbf{Affine invariant convergence}: $f(\vec{x}_T) - f^\star \leq \frac{4 C_{(f,X)}}{T+1}$.
            \item[\proofsquare] Descent lemma w.r.t. $C_{(f,X)}$ by setting $\vec{x} = \vec{x}_t, \vec{s} = \mathrm{LMO}_X(\nabla f(\vec{x}_t))$ in the supremum.
            \item \textbf{Convergence of $g(\vec{x}_t)$}: $\min_{1 \leq t \leq T} g(\vec{x}_t) \leq \frac{\nicefrac{27}{2} \cdot C_{(f, X)}}{T+1}$.
        \end{itemize}
    \end{topic}

    \begin{topic}{Newton's method}
        \begin{itemize}
            \item \textbf{Update rule}: $\vec{x}_{t+1} = \vec{x}_t - \nabla^2 f(\vec{x}_t)^{-1} \nabla f(\vec{x}_t)$.
            \item \textbf{Interp. 1}: Adaptive gradient descent.
            \item \textbf{Interp. 2}: Minimizes second-order Taylor approximation around $\vec{x}_t$: \[
                      \vec{x}_{t+1} \in \argmin_{\vec{x} \in \R^d} f(\vec{x}_t) + \nabla f(\vec{x}_t)^\top (\vec{x} - \vec{x}_t) + \frac{1}{2} (\vec{x} - \vec{x}_t)^\top \nabla^2 f(\vec{x}_t) (\vec{x} - \vec{x}_t).
                  \]
            \item \textbf{Convergence} ($\| \nabla^2 f(\vec{x})^{-1} \| \leq \frac{1}{\mu}$, $\| \nabla^2 f(\vec{x}) - \nabla^2 f(\vec{y}) \| \leq B \| \vec{x} - \vec{y} \|$): \\
                  $\| \vec{x}_{t+1} - \vec{x}^\star \| \leq \frac{B}{2 \mu} \| \vec{x}_t - \vec{x}^\star \|^2$.
            \item[\proofsquare] $\vec{x}_{t+1} - \vec{x}^\star \leq \vec{x}_t - \vec{x}^\star +
                      H(\vec{x}_t)^{-1} (\nabla f(\vec{x}^\star) - \nabla f(\vec{x}_t))$ $\Rightarrow$
                  $h(t) := \nabla f(\vec{x} + t(\vec{x}^\star - \vec{x}))$ with fundamental theorem
                  of calculus $\Rightarrow$ Take norm of both sides and simplify using $\| \mat{A}
                      \vec{x} \| = \| \mat{A} \|_2 \| \vec{x} \|$ and assumptions.
            \item Ensure bounded inverse Hessians by requiring strong convexity over $X$.
            \item If $\| \vec{x}_0 - \vec{x}^\star \| \leq \frac{\mu}{B}$, then $\| \vec{x}_T - \vec{x}^\star \| \leq
                      \frac{\mu}{B} \lft( \frac{1}{2} \rgt)^{2^T - 1}$.

        \end{itemize}
    \end{topic}

    \begin{topic}{Quasi-Newton methods}

    \end{topic}

    \begin{topic}{Subgradient method}

    \end{topic}

    \begin{topic}{Mirror descent}

    \end{topic}

    \begin{topic}{Stochastic optimization}

    \end{topic}

    \begin{topic}{Variance reduction}

    \end{topic}

    \begin{topic}{Min-max optimization}

    \end{topic}

    \begin{topic}{Variational inequalities}

    \end{topic}
\end{multicols*}

\newpage

% \begin{multicols*}{2}
%
%     \textbf{Cauchy-Schwarz}: $|\transpose{\vec{u}} \vec{v}| \leq \| \vec{u} \| \| \vec{v} \|$.
%
%     \textbf{Spectral norm}: $\| \mat{A} \| \colonequals \max_{\| \vec{v} \| = 1} \| \mat{A} \vec{v} \|$.
%
%     \textbf{Mean-value theorem}: If $a < b$ and $h: [a,b] \to \R$ continuous and differentiable in $(a,b)$, then
%     there exists $c \in (a,b)$ such that \[
%         h'(c) = \frac{h(b) - h(a)}{b-a}.
%     \]
%
%     \textbf{Fundamental theorem of calculus}: If $a < b$ and $h$ differentiable on an open domain $(a,b)$ and
%     $h'$ continuous on $[a,b]$, then \[
%         h(b) - h(a) = \int_a^b h'(t)dt.
%     \]
%
%     \textbf{Differentiable}: $f: \dom{f} \to \R^m$, where $\dom{f} \subseteq \R^d$ is differentiable at
%     $\vec{x}$ if there exists $\mat{A} \in \R^{m \times d}$ and an error function $r: \R^d \to \R^m$
%     defined in some neighborhood of $\vec{0} \in \R^d$ such that for all $\vec{y}$ in the neighborhood
%     of $\vec{x}$, \[
%         f(\vec{y}) = f(\vec{x}) + \mat{A} (\vec{y} - \vec{x}) + r(\vec{y} - \vec{x}),
%     \]
%     where \[
%         \lim_{\vec{v} \to \vec{0}} \frac{\| r(\vec{v}) \|}{\| \vec{v} \|} = \vec{0}.
%     \]
%     $\mat{A}$ is then the Jacobian of $f$ at $\vec{x}$.
%
%     \[
%         \frac{1}{y} - \frac{1}{x} = \frac{x-y}{x\cdot y}.
%     \]
%
%     \textbf{B-Lipschitz}: $f$ is $B$-Lipschitz if \[
%         \| f(\vec{x}) - f(\vec{y}) \| \leq B \| \vec{x} - \vec{y} \|,
%     \]
%     which is equivalent to bounded gradients on open domains (in closed domains, only $\Leftarrow$
%     holds) \[
%         \| \nabla f(\vec{x}) \| \leq B.
%     \]
%
%     \textbf{H\"older's inequality}: TODO
%
%     \textbf{Cosine theorem}: $2 \transpose{\vec{v}}\vec{w} = \| \vec{v} \|^2 + \| \vec{w} \|^2 - \| \vec{v} - \vec{w} \|^2$.
%
%     \textbf{Parallelogram law}: $2 \| \vec{x} \|^2 + 2 \| \vec{y} \|^2 = \| \vec{x} + \vec{y} \|^2 + \| \vec{x} - \vec{y} \|^2$.
%
%     \textbf{Titu's lemma}: $\frac{\lft( \sum_{i=1}^{d} u_i \rgt)^2}{\sum_{i=1}^{d} v_i} \leq \sum_{i=1}^{d} \frac{u_i^2}{v_i}, \forall \vec{u} \in \R^d, \vec{v} \in \R^d_{>0}$.
%
%     \begin{topic}{2 Convexity}
%         Domain must be convex. Strict convexity if inequalities become strict inequalities.
%         Equivalent definitions $\forall \vec{x},\vec{y} \in \dom{f}$:
%         \begin{itemize}
%             \item $f(\lambda \vec{x} + (1-\lambda)\vec{y}) \leq \lambda f(\vec{x}) + (1-\lambda) f(\vec{y})$.
%             \item First-order exists: $f(\vec{y}) \geq f(\vec{x}) + \transpose{\nabla f(\vec{x})} (\vec{y} -
%                       \vec{x})$.
%             \item First-order exists: $\transpose{(\nabla f(\vec{y}) - \nabla f(\vec{x}))} (\vec{y} - \vec{x}) \geq
%                       0$.
%             \item Second-order exists: $\nabla^2 f(\vec{x}) \succeq \mat{0}$.
%         \end{itemize}
%         Intuition: $f$ is above its tangential hyperplane at $(\vec{x}, f(\vec{x}))$.
%
%         \textbf{Jensen's inequality}: If $f$ convex, and $\sum_{i=1}^m \lambda_i = 1$, then \[
%             f \lft( \sum_{i=1}^{m} \lambda_i \vec{x}_i \rgt) \leq \sum_{i=1}^{m} \lambda_i f(\vec{x}_i).
%         \]
%         The other direction holds for concave functions ($-f$ is convex).
%
%         \textbf{Preserving convexity}: Max, sum, and multiplication with positive scalars preserve
%         convexity. $f \circ g$ is convex on $\dom{f \circ g} \colonequals \{ \vec{x} \in \R^m \mid
%             g(\vec{x}) \in \dom{f} \}$ if $g$ is affine.
%
%         \textbf{Local minimum}: A point $\vec{x}$, such that there exists $\epsilon > 0$ with \[
%             f(\vec{x}) \leq f(\vec{y}), \quad \forall \vec{y} \in \dom{f} \text{ satisfying } \| \vec{y} - \vec{x} \| < \epsilon.
%         \]
%
%         \textbf{Global minimum}: A point $\vec{x}$ such that \[
%             f(\vec{x}) \leq f(\vec{y}), \quad \forall \vec{y} \in \dom{f}.
%         \]
%         If $f$ is convex and differentiable over an open domain, then $\nabla f(\vec{x}) = \vec{0}$ if and
%         only if $\vec{x}$ is a global minimum.
%
%         \textbf{Sublevel set}: Let $f$ be continuous (not convex). If there exists a nonempty and
%         bounded sublevel set $f^{\leq \alpha}$, then $f$ has a global minimum.
%
%         TODO: Convex programs.
%     \end{topic}
%
%     \begin{topic}{3 Gradient descent}
%         $f$ must be differentiable, then we use the update rule: \[
%             \vec{x}_{t+1} \colonequals \vec{x}_t - \gamma_t \nabla f(\vec{x}_t).
%         \]
%
%         \textbf{Vanilla analysis}: Assuming only convexity, we get a bound on the summed error \[
%             \sum_{t=0}^{T-1} (f(\vec{x}_t) - f^\star) \leq \frac{\gamma_t}{2} \sum_{t=0}^{T-1} \| \nabla f(\vec{x}_t) \|^2 + \frac{1}{2 \gamma_t} \| \vec{x}_0 - \vec{x}^\star \|^2.
%         \]
%         \underline{Proof} by using first-order convexity on $\vec{x}_t$ and $\vec{x}^\star$, and rewrite the gradient
%         descent update rule.
%
%         \textbf{Lipschitz functions} ($\mathcal{O}(\nicefrac{1}{\epsilon^2})$): Setting
%         $\gamma \colonequals \nicefrac{R}{B \sqrt{T}}$, we get \[
%             \frac{1}{T} \sum_{t=0}^{T-1} (f(\vec{x}_t) - f^\star) \leq \frac{RB}{\sqrt{T}}.
%         \]
%         Using bound $\| \vec{x}_0 - \vec{x}^\star \| \leq R$.
%     \end{topic}
%
%     \begin{topic}{3 Smooth functions}
%         $L$-smooth with equivalent definitions $\forall \vec{x}, \vec{y} \in X$:
%         \begin{itemize}
%             \item $f(\vec{y}) \leq f(\vec{x}) + \transpose{\nabla f(\vec{x})} (\vec{y} - \vec{x}) + \frac{L}{2} \| \vec{x} - \vec{y} \|^2$.
%             \item Lemma 3.3: $\frac{L}{2} \transpose{\vec{x}} \vec{x} - f(\vec{x})$ is convex.
%             \item Lemma 3.5: $\| \nabla f(\vec{x}) - \nabla f(\vec{y}) \| \leq L \| \vec{x} - \vec{y} \|$.
%             \item Lemma 6.1: $\| \nabla^2 f(\vec{x}) \| \leq L$ ($\Leftarrow$ only if $X$ is open).
%             \item TODO: Add more definitions/implications.
%         \end{itemize}
%         Intuition: $f$ is below a not-too-steep tangential paraboloid at $(\vec{x}, f(\vec{x}))$.
%
%         \textbf{Affine functions} (Lemma 3.4): $f(\vec{x}) = \transpose{\vec{x}} \mat{Q} \vec{x} +
%             \transpose{\vec{b}} \vec{x} + c$ is smooth with parameter $2 \| \mat{Q} \|$ if $\mat{Q}$ is
%         symmetric.
%
%         \textbf{Sufficient decrease} (Lemma 3.7): Choosing $\gamma \colonequals \nicefrac{1}{L}$, gradient descent satisfies \[
%             f(\vec{x}_{t+1}) \leq f(\vec{x}_t) - \frac{1}{2L} \| \nabla f(\vec{x}_t) \|^2, \quad t \geq 0.
%         \]
%         (Already holds if $f$ is $L$-smooth over line segment connecting $\vec{x}_t$ and $\vec{x}_{t+1}$.)
%         \underline{Proof} by first definition of smoothness, cosine theorem, and gradient descent update rule.
%
%         \textbf{Convergence} $(\mathcal{O}(\nicefrac{1}{\epsilon}))$ (Theorem 3.8): Choosing $\gamma \colonequals \nicefrac{1}{L}$, gradient descent yields \[
%             f(\vec{x}_T) - f^\star \leq \frac{L}{2T} \| \vec{x}_0 - \vec{x}^\star \|^2, \quad T > 0.
%         \]
%         \underline{Proof} by starting from vanilla analysis and bounding gradient sum with sufficient decrease.
%
%         Accelerated gradient descent achieves $\mathcal{O}(\nicefrac{1}{\sqrt{\epsilon}})$ by using an
%         intermediate variable.
%     \end{topic}
%
%     \begin{topic}{3 Strongly convex functions}
%         $\mu$-strongly convex with equivalent definitions $\forall \vec{x}, \vec{y} \in X$:
%         \begin{itemize}
%             \item $f(\vec{y}) \geq f(\vec{x}) + \transpose{\nabla f(\vec{x})} (\vec{y} - \vec{x}) + \frac{\mu}{2} \| \vec{x} - \vec{y} \|^2$.
%             \item Lemma 3.11: $f(\vec{x}) - \frac{\mu}{2} \transpose{\vec{x}} \vec{x}$ is convex.
%             \item TODO: Add more definitions/implications.
%         \end{itemize}
%         Intuition: $f$ is above a not-too-flat tangential paraboloid at $(\vec{x}, f(\vec{x}))$.
%
%         \textbf{Strict convexity} (Lemma 3.12): If $f$ is $\mu$-strongly convex, then $f$ is strictly convex.
%
%         \textbf{Geometrically decreasing distances} (Theorem 3.14): Choosing $\gamma \colonequals \nicefrac{1}{L}$, gradient descent satisfies \[
%             \| \vec{x}_{t+1} - \vec{x}^\star \|^2 \leq \lft( 1 - \frac{\mu}{L} \rgt) \| \vec{x}_t - \vec{x}^\star \|^2, \quad t \geq 0.
%         \]
%         \underline{Proof} by rewriting vanilla analysis with first definition of strong convexity and
%         sufficient decrease.
%
%         \textbf{Convergence} $\mathcal{O}(\log \nicefrac{1}{\epsilon})$ (Theorem 3.14): Choosing $\gamma \colonequals \nicefrac{1}{L}$, gradient descent yields \[
%             f(\vec{x}_T) - f^\star \leq \frac{L}{2} \lft( 1 - \frac{\mu}{L} \rgt)^T \| \vec{x}_0 - \vec{x}^\star \|^2, \quad T > 0.
%         \]
%         \underline{Proof} by using geometrically decreasing distances and smoothness with
%         $\nabla f(\vec{x}^\star) = \vec{0}$.
%     \end{topic}
%
%     \begin{topic}{4 Projected gradient descent}
%         Optimization within closed convex subset $X \subseteq \R^d$.
%         \begin{align*}
%             \vec{y}_{t+1} & \colonequals \vec{x}_t - \gamma \nabla f(\vec{x})                                                       \\
%             \vec{x}_{t+1} & \colonequals \Pi_X(\vec{y}_{t+1}) \colonequals \argmin_{\vec{x} \in X} \| \vec{x} - \vec{y}_{y+1} \|^2.
%         \end{align*}
%         After every step, project back onto $X$.
%
%         \textbf{Projection properties} (Fact 4.1): $\vec{x} - \Pi_X(\vec{y})$ and $\vec{y} - \Pi_X(\vec{y})$ form an obtuse angle,
%         \begin{itemize}
%             \item $\transpose{(\vec{x} - \Pi_X(\vec{y}))}(\vec{y} - \Pi_X(\vec{y})) \leq 0$.
%             \item $\| \vec{x} - \Pi_X(\vec{y}) \|^2 + \| \vec{y} - \Pi_X(\vec{y}) \|^2 \leq \| \vec{x} - \vec{y} \|^2$.
%         \end{itemize}
%
%         \textbf{Lipschitz functions} ($\mathcal{O}(\nicefrac{1}{\epsilon^2})$) (Theorem 4.2): Same bound as gradient
%         descent. \underline{Proof} by replacing $\vec{x}_{t+1}$ by $\vec{y}_{t+1}$ in the vanilla
%         analysis and using the second projection property with $\vec{x} = \vec{x}^\star$ and
%         $\vec{y} = \vec{y}_{t+1}$.
%
%         \textbf{Sufficient decrease} (Lemma 4.3): If $f$ is $L$-smooth,
%         choosing stepsize $\gamma \colonequals \nicefrac{1}{L}$, we get \[
%             f(\vec{x}_{t+1}) \leq f(\vec{x}_t) - \frac{1}{2L} \| \nabla f(\vec{x}_t) \|^2 + \frac{L}{2} \| \vec{y}_{t+1} - \vec{x}_{t+1} \|^2.
%         \]
%         \underline{Proof} by the same as gradient descent, but then with projection step.
%
%         \textbf{Smooth functions} ($\mathcal{O}(\nicefrac{1}{\epsilon})$) (Theorem 4.4): Same result
%         as in gradient descent. \underline{Proof} by compensating for the extra term in sufficient
%         decrease by the vanilla analysis.
%
%         \textbf{Strongly convex} ($\mathcal{O}(\log \nicefrac{1}{\epsilon})$) (Theorem 4.5):
%         Decreasing distances still holds, but extra term in convergence bound when choosing
%         $\gamma \colonequals \nicefrac{1}{L}$,
%         \begin{align*}
%             f(\vec{x}_T) - f^\star & \leq \| \nabla f(\vec{x}^\star) \| \lft( 1 - \frac{\mu}{L} \rgt)^{\nicefrac{T}{2}} \| \vec{x}_0 - \vec{x}^\star \| \\
%                                    & \quad + \frac{L}{2} \lft( 1 - \frac{\mu}{L} \rgt)^T \| \vec{x}_0 - \vec{x}^\star \|^2.
%         \end{align*}
%         This is due to the fact that we cannot use $\nabla f(\vec{x}^\star) = \vec{0}$ in the constrained
%         case.
%     \end{topic}
%
%     \begin{topic}{5 Coordinate descent}
%         Update only one coordinate of $\vec{x}_t$ at a time, meaning that we only need to compute the
%         gradient of one coordinate of $\nabla f(\vec{x}_t)$.
%
%         \textbf{PL inequality}: $f$ has a global minimum $\vec{x}^\star$. Definition $\forall \vec{x}
%             \in X$: \[
%             \frac{1}{2} \| \nabla f(\vec{x}) \|^2 \geq \mu (f(\vec{x}) - f(\vec{x}^\star)).
%         \]
%
%         \textbf{Strong convexity $\Rightarrow$ PL inequality} (Lemma 5.2).
%
%         \textbf{Coordinate-wise smoothness}: $f$ is coordinate-wise smooth with $\mathcal{L} =
%             [L_1, \ldots, L_d] \in \R_+^d$ if $\forall \vec{x}, \vec{y} \in X, i \in [d]$: \[
%             f(\vec{x} + \lambda \vec{e}_i) \leq f(\vec{x}) + \lambda \nabla_i f(\vec{x}) + \frac{L_i}{2} \lambda^2.
%         \]
%         This gives a more fine-grained picture of $f$ than smoothness. It might be the case that all $L_i$
%         are significantly smaller than the best possible $L$-smoothness.
%
%         \textbf{Update rule}:
%         \begin{align*}
%              & \text{choose an active coordinate $i \in [d]$}                                   \\
%              & \vec{x}_{t+1} \colonequals \vec{x}_t - \gamma_i \nabla_i f(\vec{x}_t) \vec{e}_i.
%         \end{align*}
%
%         \textbf{Coordinate-wise sufficient decrease} (Lemma 5.5): With stepsize $\gamma_i = \nicefrac{1}{L_i}$, coordinate descent satisfies \[
%             f(\vec{x}_{t+1}) \leq f(\vec{x}_t) - \frac{1}{2L_i} | \nabla_i f(\vec{x}_t) |^2.
%         \]
%
%         \textbf{Randomized coordinate descent convergence} (Theorem 5.6): $f$ is coordinate-wise
%         smooth with $L$ and satisfies PL-inequality with $\mu$. Choosing $\gamma_i = \frac{1}{L}$, we
%         get \[
%             \E[f(\vec{x}_T) - f^\star] \leq \lft( 1 - \frac{\mu}{dL} \rgt)^T (f(\vec{x}_0) - f^\star).
%         \]
%         \underline{Proof} by using coordinate-wise sufficient decrease and taking expectation with
%         respect to $i$ on both sides. Then, expectation over $\vec{x}_t$ to remove condition.
%
%         \textbf{Importance sampling convergence} (Theorem 5.7): Sample $i$ with probability $\nicefrac{L_i}{\sum_{j=1}^{d} L_j}$. Let $\bar{L} = \nicefrac{1}{d} \sum_{i=1}^{d} L_i$. Choosing $\gamma_i = \nicefrac{1}{L_i}$, we get \[
%             \E[f(\vec{x}_T) - f^\star] \leq \lft( 1 - \frac{\mu}{d \bar{L}} \rgt)^T (f(\vec{x}_0) - f^\star).
%         \]
%         \underline{Proof} by the same method as randomized coordinate descent.
%
%         \textbf{Steepest coordinate descent convergence} (Corollary 5.8): Choose index with largest
%         absolute gradient. Same conditions as randomized coordinate descent. Then, we get \[
%             f(\vec{x}_T) - f^\star \leq \lft( 1 - \frac{\mu}{dL} \rgt)^T (f(\vec{x}_0) - f^\star).
%         \]
%
%         TODO: Strong convexity with respect to $\ell_1$-norm.
%
%         \textbf{Greedy coordinate descent}: Choose the index by one of the above methods, but then
%         perform a line search over that coordinate and minimize by solving a 1-dimensional
%         optimization problem (easy). This does not require $f$ to be differentiable. But, this does
%         not always return the global minimum, since there are functions with points where it can make
%         no progress.
%
%         Theorem 5.11: Let $f$ be of the form $f(\vec{x}) \colonequals g(\vec{x}) + h(\vec{x})$ with
%         $h(\vec{x}) = \sum_{i} h_i(x_i)$, $h_i$ convex, and $g$ convex and differentiable. If $\vec{x}$ is
%         a point that greedy coordinate descent cannot make progress in any coordinate, then $\vec{x}$ is a
%         global minimum of $f$.
%     \end{topic}
%
%     \begin{topic}{6 Nonconvex functions}
%         For nonconvex functions, gradient descent may get stuck in a local minimum, stuck in a saddle
%         point (flat region), or infinitely decrease, but never reach a critical point (e.g. $\nicefrac{1}{e^x}$).
%
%         \textbf{Gradient convergence} (Theorem 6.2): $f$ is $L$-smooth. Choosing $\gamma \colonequals \nicefrac{1}{L}$, then \[
%             \frac{1}{T} \sum_{t=0}^{T-1} \| \nabla f(\vec{x}_t) \|^2 \leq \frac{2L}{T} (f(\vec{x}_0) - f^\star).
%         \]
%         In particular, $\| \nabla f(\vec{x}_t) \|^2 \leq \frac{2L}{T} (f(\vec{x}_0) - f^\star)$ for some $t
%             \in [T-1]$, and $\lim_{t \to \infty} \| \nabla f(\vec{x}_t) \|^2 = 0$. This does not mean that it
%         converges to a critical point, since it may never reach a point with 0 gradient, but only move
%         toward it asymptotically. \underline{Proof} by sufficient decrease, which does not require
%         convexity.
%
%         \textbf{$\gamma \colonequals \nicefrac{1}{L}$ does not overshoot critical points} (Lemma 6.3).
%
%         TODO: Trajectory analysis.
%     \end{topic}
%
%     \begin{topic}{7 The Frank-Wolfe algorithm}
%         Constrained optimization algorithm without projection (which can be very complex) by making
%         use of linear minimization oracle: \[
%             \mathrm{LMO}_X(\vec{g}) \colonequals \argmin_{\vec{z} \in X} \transpose{\vec{g}} \vec{z}.
%         \]
%         The algorithm is then
%         \begin{align*}
%             \vec{s}_t     & \colonequals \mathrm{LMO}_X(\nabla f(\vec{x}_t))            \\
%             \vec{x}_{t+1} & \colonequals (1 - \gamma_t) \vec{x}_t + \gamma_t \vec{s}_t.
%         \end{align*}
%         Reduces non-linear constrained optimization to linear optimization over the same set.
%         Rationale is that the gradient defines the best linear approximation of $f$ at $\vec{x}_t$.
%
%         \textbf{Properties}: (1) iterates are always feasible, i.e., in $X$, (2) projection-free, which can be
%         very complex, and (3) iterates have a simple sparse representation, i.e., $\vec{x}_t$ is
%         always a convex combination of $\vec{x}_0$ and the minimizers $\vec{s}_{1:t-1}$.
%
%         Let $X = \mathrm{conv}(\mathcal{A})$, then every $\vec{s} \colonequals \mathrm{LMO}_X(\vec{g}) \in
%             \mathrm{conv}(X)$ is a convex combination of atoms, $\vec{s} = \sum_{i=1}^{n} \lambda_i \vec{a}_i$
%         with $\sum_{i=1}^{n} \lambda_i = 1$. Furthermore, there is always an atom in $\mathcal{A}$ that
%         minimizes the LMO.
%
%         \textbf{$\ell_1$-ball}: The LMO for $X = \{ \vec{x} \in \R^d \mid \| \vec{x} \|_1 \leq 1 \}$ is given by \[
%             \mathrm{LMO}_X(\vec{g}) = -\mathrm{sign}(g_i) \vec{e}_i \text{ with } i \colonequals \argmax_{i \in [d]} | g_i |.
%         \]
%
%         TODO: Spectahedron.
%
%         \textbf{Duality gap} (Lemma 7.2): We can easily compute an upper bound of the optimality gap, \[
%             g(\vec{x}) \colonequals \transpose{\nabla f(\vec{x})} (\vec{x} - \vec{s}) \geq f(\vec{x}) - f^\star,
%         \]
%         with $\vec{s} \colonequals \mathrm{LMO}_X(\nabla f(\vec{x}))$. At any optimal point
%         $\vec{x}^\star$, $g(\vec{x}^\star) = 0$. \underline{Proof} by using $\transpose{\nabla f(\vec{x})}
%             \vec{s} \leq \transpose{\nabla f(\vec{x})} \vec{x}^\star$, and the first-order characterization of
%         convexity.
%
%         \textbf{Descent} (Lemma 7.4): For a step $\vec{x}_{t+1} \colonequals \vec{x}_t - \gamma_t (\vec{s} - \vec{x}_t)$ with stepsize $\gamma_t \in [0,1]$, it holds that \[
%             f(\vec{x}_{t+1}) \leq f(\vec{x}_t) - \gamma_t g(\vec{x}_t) + \gamma_t^2 \frac{L}{2} \| \vec{s} - \vec{x}_t \|^2,
%         \]
%         with $\vec{s} \colonequals \mathrm{LMO}_X(\nabla f(\vec{x}))$. \underline{Proof} by first
%         definition of smoothness and duality gap.
%
%         \textbf{Convergence analysis} ($\mathcal{O}(\nicefrac{1}{\epsilon})$) (Theorem 7.3): $f$ is $L$-smooth and convex. With $\gamma_t = \nicefrac{2}{t+2}$, Frank-Wolfe yields \[
%             f(\vec{x}_T) - f^\star \leq \frac{2L \mathrm{diam}(X)^2}{T+1}.
%         \]
%         \underline{Proof} by duality gap and descent lemma, and then induction.
%
%         \textbf{Linear search stepsize}: Choose $\gamma_t \in [0,1]$ such that the progress is maximized, \[
%             \gamma_t \colonequals \argmin_{\gamma \in [0,1]} f((1-\gamma) \vec{x}_t + \gamma \vec{s}).
%         \]
%         The descent lemma still holds for this stepsize, since this stepsize can only be better than a
%         predetermined stepsize. And, thus the convergence also holds.
%
%         TODO: Gap-based stepsize.
%
%         TODO: Affine invariance.
%
%         TODO: Curvature constant.
%
%     \end{topic}
%
%     \begin{topic}{Subgradient method}
%         More general notion of the gradient for functions that are non-smooth.
%
%         \textbf{Subgradient}: $\vec{g}$ is a subgradient of $f$ at $\vec{x}$ if \[
%             f(\vec{y}) \geq f(\vec{x}) \transpose{\vec{g}} (\vec{y} - \vec{x}), \quad \forall \vec{y} \in \dom{f}.
%         \]
%         $\partial f(\vec{x}) \subseteq \R^d$ is called the subdifferential and $\vec{g} \in \partial f(\vec{x})$.
%
%         If $f$ is differentiable at $\vec{x}$, then $\partial f(\vec{x}) \subseteq \{ \nabla f(\vec{x})
%             \}$.
%
%         \textbf{Convexity characterization}:
%         \begin{itemize}
%             \item If $f$ is convex, then $\partial f(\vec{x}) \neq \emptyset$ for all $\vec{x}$ in the relative
%                   interior of $\dom{f}$.
%             \item If $\dom{f}$ is convex and $\partial f(\vec{x}) \neq \emptyset$ for all $\vec{x} \in \dom{f}$, then
%                   $f$ is convex.
%         \end{itemize}
%
%         \textbf{Optimality condition}: If $\vec{0} \in \partial f(\vec{x})$, then $\vec{x}$ is a global minimum.
%
%         \textbf{Subgradient calculus}:
%         \begin{itemize}
%             \item Conic combination: Let $h(\vec{x}) = \alpha f(\vec{x}) + \beta g(\vec{x})$ with $\alpha, \beta >
%                       0$, then \[
%                       \partial h(\vec{x}) = \alpha \partial f(\vec{x}) + \beta \partial g(\vec{x}).
%                   \]
%             \item Affine transformation: Let $h(\vec{x}) = f(\mat{A} \vec{x} + \vec{b})$, then \[
%                       \partial h(\vec{x}) = \transpose{\mat{A}} \partial f(\mat{A} \vec{x} + \vec{b}).
%                   \]
%             \item Pointwise maximum: Let $h(\vec{x}) = \max_{i \in [m]} f_i(\vec{x})$, then \[
%                       \partial h(\vec{x}) = \mathrm{conv}(\{ \partial f_i(\vec{x}) \mid f_i(\vec{x}) = h(\vec{x}) \}).
%                   \]
%         \end{itemize}
%
%         \textbf{Subgradient method update rule}: $\vec{x}_{t+1} = \Pi_{\mathcal{X}}(\vec{x}_t - \gamma_t \gamma_t), \vec{g}_t \in \partial f(\vec{x}_t)$.
%
%         \textbf{``Descent'' lemma}: If $f$ is convex, then for any optimal solution $\vec{x}^\star$, we have \[
%             \| \vec{x}_{t+1} - \vec{x}^\star \|^2 \leq \| \vec{x}_t - \vec{x}^\star \|^2 - 2 \gamma_t (f(\vec{x}_t) - f^\star) + \gamma_t^2 \| \vec{g}_t \|^2.
%         \]
%         \underline{Proof}: Update rule, remove projection, cosine theorem, convexity.
%
%         \textbf{Convergence}: \[
%             \min_{t \in [T]} f(\vec{x}_t) - f^\star \leq \frac{\| \vec{x}_0 - \vec{x}^\star \|^2 + \sum_{t=0}^{T-1} \gamma_t^2 \|\vec{g}_t\|^2}{2 \sum_{t=0}^{T-1} \gamma_t}.
%         \]
%         \begin{itemize}
%             \item If $\gamma \colonequals \nicefrac{R}{B \sqrt{T}}$, then the subgradient method satisfies \[
%                       \min_{t \in [T]} f(\vec{x}_t) - f^\star \leq \frac{BR}{\sqrt{T}}.
%                   \]
%                   To achieve $\epsilon$-optimality, need $\mathcal{O}(\nicefrac{B^2 R^2}{\epsilon^2})$ iterations.
%             \item If $\mu$-strongly convex and $\gamma \colonequals \nicefrac{2}{\mu(t+1)}$, then the subgradient
%                   method satisfies \[
%                       \min_{t \in [T]} f(\vec{x}_t) - f^\star \leq \frac{2B^2}{\mu(T+1)}.
%                   \]
%                   To achieve $\epsilon$-optimality, need $\mathcal{O}(\nicefrac{B^2}{\mu \epsilon})$ iterations.
%         \end{itemize}
%         The above is much worse than gradient descent and cannot be improved.
%
%     \end{topic}
%
%     \begin{topic}{Mirror descent}
%         \textbf{Norm} $\| \cdot \|$ definition:
%         \begin{enumerate}
%             \item (Positive definiteness) $\| \vec{x} \| = 0$ if and only if $\vec{x} = \vec{0}$.
%             \item (Positive homogeneity) $\| \alpha \vec{x} \| = |\alpha| \| \vec{x} \|$.
%             \item (Subadditivity) $\| \vec{x} + \vec{y} \| \leq \| \vec{x} \| + \| \vec{y} \|$.
%         \end{enumerate}
%
%         \textbf{Dual norm} $\| \cdot \|_*$ definition: Satisfies the properties of a norm and \[
%             \| \vec{y} \|_* \colonequals \max_{\| \vec{x} \| \leq 1} \langle \vec{x}, \vec{y} \rangle.
%         \]
%         For $p \geq 1$ and $\nicefrac{1}{p} + \nicefrac{1}{q} = 1$, we have the following norms with their
%         dual norms: \[
%             \| \vec{x} \|_p = \lft( \sum_{i=1}^{d} |x_i|^p \rgt)^{\nicefrac{1}{p}}, \quad \| \cdot \|_{p,*} = \| \cdot \|_q.
%         \]
%         We have the following inequalities between norms: \[
%             \frac{1}{\sqrt{d}} \| \vec{x} \|_2 \leq \| \vec{x} \|_\infty \leq \| \vec{x} \|_2 \leq \| \vec{x} \|_1 \leq \sqrt{d} \| \vec{x} \|_2.
%         \]
%
%         \textbf{Bregman divergence} definition: Let $\omega$ be continuously differentiable and 1-strongly convex
%         w.r.t. some norm $\| \cdot \|$. The Bregman divergence $V_{\omega}$ is then defined as: \[
%             V_{\omega}(\vec{x}, \vec{y}) \colonequals \omega(\vec{x}) - \omega(\vec{y}) - \nabla \omega(\vec{y})^\top (\vec{x} - \vec{y}).
%         \]
%         Properties:
%         \begin{enumerate}
%             \item (Non-negativity) $V_{\omega}(\vec{x}, \vec{y}) \geq 0$.
%             \item (Convexity) $V_{\omega}(\vec{x}, \vec{y})$ is convex in $\vec{x}$.
%             \item (Positivity) $V_{\omega}(\vec{x}, \vec{y}) = 0$ if and only if $\vec{x} = \vec{y}$.
%             \item $V_{\omega}(\vec{x}, \vec{y}) \geq \frac{1}{2} \| \vec{x} - \vec{y} \|^2$.
%             \item (Three-point identity) $V_{\omega}(\vec{x}, \vec{z}) = V_{\omega}(\vec{x}, \vec{y}) + V_{\omega}(\vec{y}, \vec{z}) - \langle \nabla \omega(\vec{z}), \nabla \omega(\vec{y}), \vec{x} - \vec{y} \rangle$.
%         \end{enumerate}
%
%         \textbf{Mirror descent}: Update rule: \[
%             \vec{x}_{t+1} = \argmin_{\vec{x} \in X} \lft\{ V_{\omega}(\vec{x}, \vec{x}_t) + \langle \gamma_t \vec{g}_t, \vec{x} \rangle \rgt\}, \quad \vec{g}_t \in \partial f(\vec{x}_t).
%         \]
%         Lemma (TODO): Let $f$ be convex, then: \[
%             \gamma_t (f(\vec{x}_t) - f^\star) \leq V_{\omega}(\vec{x}^\star, \vec{x}_t) - V_{\omega}(\vec{x}^\star, \vec{x}_{t+1}) + \frac{\gamma_t^2}{2} \| \vec{g}_t \|^2_*.
%         \]
%         \textbf{Convergence}: \[
%             \min_{t \in [T]} f(\vec{x}_t) - f^\star \leq \frac{V_{\omega}(\vec{x}^\star, \vec{x}_0) + \frac{1}{2} \sum_{t=0}^{T-1} \gamma_t^2 \| \vec{g}_t \|_*^2}{\sum_{t=0}^{T-1} \gamma_t}.
%         \]
%         Suppose $f$ is $B$-Lipschitz continuous such that $|f(\vec{x}) - f(\vec{y})| \leq B \| \vec{x} -
%             \vec{y} \|, \forall \vec{x}, \vec{y} \in X$. Namely, $\| \vec{g} \|_* \leq B, \forall \vec{g} \in
%             \partial f(\vec{x}), \vec{x} \in X$. Furthermore, let $R^2 = \sup_{\vec{x}} V_{\omega}(\vec{x},
%             \vec{x}_0)$ and set \[
%             \gamma = \frac{\sqrt{2} R}{B \sqrt{T}}.
%         \]
%         Then, we have convergence rate \[
%             \min_{t \in [T]} f(\vec{x}_t) - f^\star \leq \mathcal{O}\lft( \frac{BR}{\sqrt{T}} \rgt).
%         \]
%         This is equivalent to the convergence rate of subgradient descent, but for a more general notion of
%         norm. Thus, in special cases, it will result in faster convergence.
%     \end{topic}
%
%     \begin{topic}{Smoothing}
%         \textbf{Conjugate function}: \[
%             f^*(\vec{y}) = \sup_{\vec{x} \in \dom{f}} \lft\{ \vec{x}^\top \vec{y} - f(\vec{x}) \rgt\}.
%         \]
%         Properties:
%         \begin{enumerate}
%             \item (Duality) If $f$ is continuous and convex, then $f^{**} = f$.
%             \item (Fenchel's inequality) $f(\vec{x}) + f^*(\vec{y}) \geq \vec{x}^\top \vec{y}$.
%             \item If $f$ and $g$ are continuous and convex, then $(f+g)^*(\vec{x}) = \inf_{\vec{y}} \lft\{
%                       f^*(\vec{y}) + g^*(\vec{x} - \vec{y}) \rgt\}$.
%             \item If $f$ is $\mu$-strongly convex, then $f^*$ is differentiable and $\nicefrac{1}{\mu}$-smooth.
%         \end{enumerate}
%
%         \textbf{Nesterov smoothing}: Approximate non-smooth $f$ by \[
%             f_{\mu}(\vec{x}) = \max{\vec{y} \in \dom{f^*}} \lft\{ \vec{x}^\top \vec{y} - f^*(\vec{y}) - \mu \cdot d(\vec{y}) \rgt\},
%         \]
%         where $d$ is a proximity function (1-strongly convex and non-negative). $f_{\mu}$ is
%         $\nicefrac{1}{\mu}$-smooth and approximates $f$ by \[
%             f(\vec{x}) - \mu D^2 \leq f_{\mu}(\vec{x}) \leq f(\vec{x}), \quad D^2 = \max_{\vec{y}} d(\vec{y}).
%         \]
%         Applying accelerated gradient descent to optimize the smoothed problem, we get the following
%         convergence rate: \[
%             f(\vec{x}_t) - f^\star \leq \mathcal{O}\lft( \mu D^2 + \frac{R^2}{\mu t^2} \rgt).
%         \]
%         This is faster than applying subgradient descent.
%
%         \textbf{Moreau-Yosida smoothing}: Approximate non-smooth $f$ by \[
%             f_{\mu}(\vec{x}) = \min_{\vec{y}} \lft\{ f(\vec{y}) + \frac{1}{2 \mu} \| \vec{x} - \vec{y} \|_2^2 \rgt\}.
%         \]
%         $f_{\mu}$ is the Moreau envelope of $f$. $f_{\mu}$ is $\nicefrac{1}{\mu}$-smooth and
%         minimizes exactly, i.e., $\min_{\vec{x}} f(\vec{x}) = \min_{\vec{x}} f_{\mu}(\vec{x})$.
%     \end{topic}
%
%     \begin{topic}{Proximal algorithms}
%         \textbf{Proximal operator}: $f$ is convex: \[
%             \mathrm{prox}_f(\vec{x}) \colonequals \argmin_{\vec{y}} \lft\{ f(\vec{y}) + \frac{1}{2} \| \vec{x} - \vec{y} \|_2^2 \rgt\}.
%         \]
%
%         \textbf{Proximal point algorithm}: \[
%             \vec{x}_{t+1} = \mathrm{prox}_{\lambda_t f}(\vec{x}_t).
%         \]
%         \textbf{Convergence}: \[
%             f(\vec{x}_{T+1}) - f^\star \leq \frac{\| \vec{x}_0 - \vec{x}^\star \|_2^2}{2 \sum_{t=0}^{T} \lambda_t}.
%         \]
%         If $\lambda_t$ is constant, PPA achieves $\mathcal{O}(\nicefrac{1}{t})$ convergence.
%
%         \textbf{Proximal gradient method}: Assume convex composite optimization problem, where $f$ and $g$ are convex: \[
%             \min_{\vec{x}} F(\vec{x}) \colonequals f(\vec{x}) + g(\vec{x}).
%         \]
%         Update rule: \[
%             \vec{x}_{t+1} = \mathrm{prox}_{\gamma_t g} (\vec{x}_t - \gamma_t \nabla f(\vec{x}_t)).
%         \]
%         \textbf{Convergence}: Let $f$ be $L$-smooth and convex and $g$ convex. Let $\gamma_t = \nicefrac{1}{L}$, then \[
%             F(\vec{x}_t) - F^\star \leq \frac{L \| \vec{x}_0 - \vec{x}^\star \|_2^2}{2t}.
%         \]
%         This is nearly the same convergence rate as GD, despite $F$ being possibly non-smooth.
%     \end{topic}
%
% \end{multicols*}

\end{document}
