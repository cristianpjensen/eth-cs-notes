\section{Paradigms of data science}

Let $\{ \vec{x}_1, \ldots, \vec{x}_n \}$ be \iid samples, generated by an unknown distribution $P$.
Assume that this distribution is in a distribution family, \[
    \mathcal{H} = \{ p(\cdot \mid \vec{\theta}) \mid \vec{\theta} \in \Theta \}.
\]
The goal is to learn the parameters $\vec{\theta}$ that fit the data $\{ \vec{x}_1, \ldots,
    \vec{x}_n \}$ best.

\paragraph{Frequentism.}

In frequentism, the MLE (\textit{\textbf{M}aximum \textbf{L}ikelihood \textbf{E}stimator})
parameters maximize the following,
\begin{align*}
    \vec{\theta}^\star & \in \argmax_{\vec{\theta} \in \Theta} \log p(\{ \vec{x}_1, \ldots, \vec{x}_n \} \mid \vec{\theta}) \\
                       & = \argmax_{\vec{\theta} \in \Theta} \sum_{i=1}^{n} \log p(\vec{x}_i \mid \vec{\theta}).
\end{align*}

\paragraph{Bayesianism.}

Bayesianism assumes that there is a prior over distributions. The MAP (\textit{\textbf{M}aximum
    \textbf{A} \textbf{P}osteriori}) parameters maximize the following,
\begin{align*}
    \vec{\theta}^\star & \in \argmax_{\vec{\theta} \in \Theta} \log p(\vec{\theta} \mid \mat{X})                                                                         \\
                       & = \argmax_{\vec{\theta} \in \Theta} \log p(\{ \vec{x}_1, \ldots, \vec{x}_n \} \mid \vec{\theta}) \cdot p(\vec{\theta}) \margintag{Bayes' rule.} \\
                       & = \argmax_{\vec{\theta} \in \Theta} \log p(\vec{\theta}) + \sum_{i=1}^{n} \log p(\vec{x}_i \mid \vec{\theta}).
\end{align*}
In practice, the prior acts as a regularization term, such that the posterior does not move too far from the prior.

\paragraph{Statistical learning.}

Now, assume that we have labeled samples $(\vec{x}, y) \in \mathcal{X} \times \mathcal{Y}$, where
$y$ is the target variable. Let $\ell: \mathcal{Y} \times \mathcal{Y} \to \R$ be a loss function.
For a predictor function $f: \mathcal{X} \to \mathcal{Y}$, we define its risk as the expected loss, \[
    \mathcal{R}(f) \doteq \E_{X, Y} [\ell(y, f(\vec{x}))].
\]
In statistical learning, we want to find a function that minimizes the risk. However, since the
distribution over $X,Y$ is unknown, we cannot compute $\mathcal{R}(f)$ directly. Instead, we use
the empirical risk as a surrogate, \[
    \hat{\mathcal{R}}(f) \doteq \frac{1}{n} \sum_{i=1}^{n} \ell(y_i, f(\vec{x}_i)).
\]
The goal is to obtain the empirical risk minimizer, \[
    f^\star \in \argmin_{f \in \mathcal{F}} \hat{\mathcal{R}}(f),
\]
where $\mathcal{F}$ is a family of functions that we assume $f$ belongs to.
